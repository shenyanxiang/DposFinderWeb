{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建jobs.sql文件，用于创建jobs表\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, DateTime\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# 创建数据库引擎，'sqlite:///jobs.db' 指定了数据库的路径为当前目录下的 jobs.db 文件\n",
    "engine = create_engine('sqlite:///jobs.db')\n",
    "\n",
    "# 创建元数据实例\n",
    "metadata = MetaData()\n",
    "\n",
    "# 定义表\n",
    "jobs = Table('jobs', metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('job_id', String(50), unique=True),\n",
    "    Column('task', String(10)),\n",
    "    Column('ip', String(50)),\n",
    "    Column('num_sequence', Integer),\n",
    "    Column('status', String(30)),\n",
    "    Column('email', String(30)),\n",
    "    Column('submit_time', DateTime),\n",
    ")\n",
    "\n",
    "# 创建表\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# 创建数据库引擎，'sqlite:///jobs.db' 指定了数据库的路径为当前目录下的 jobs.db 文件\n",
    "engine = create_engine('sqlite:///jobs.db')\n",
    "\n",
    "# 创建元数据实例\n",
    "metadata = MetaData()\n",
    "\n",
    "# 获取 jobs 表对象\n",
    "jobs = Table('jobs', metadata)\n",
    "\n",
    "# 创建数据库会话\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# 执行删除操作\n",
    "session.query(jobs).delete()\n",
    "\n",
    "# 提交事务\n",
    "session.commit()\n",
    "\n",
    "# 关闭会话\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 遍历./dpos_db/valid_dpos目录下的所有子目录，将每个子目录中的sequence.fasta文件写入到published_dpos.fasta文件中\n",
    "def write_published_dpos():\n",
    "    with open('published_dpos.fasta', 'w') as f:\n",
    "        for root, dirs, files in os.walk('./dpos_db/valid_dpos'):\n",
    "            for file in files:\n",
    "                if file == 'sequence.fasta':\n",
    "                    with open(os.path.join(root, file), 'r') as sequence:\n",
    "                        f.write(sequence.read())\n",
    "                        f.write('\\n')\n",
    "\n",
    "write_published_dpos()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez, SeqIO\n",
    "\n",
    "Entrez.email = 'shenyanxiang@sjtu.edu.cn'\n",
    "\n",
    "# 读取包含蛋白质 accession 号的文件\n",
    "with open('dpos_database.txt', 'r') as file:\n",
    "    protein_accessions = file.read().splitlines()\n",
    "\n",
    "# 根据蛋白质 accession 号获取对应的基因组 accession 号\n",
    "genome_accessions = []\n",
    "for protein_accession in protein_accessions:\n",
    "    handle = Entrez.efetch(db='protein', id=protein_accession, rettype='gb', retmode='text')\n",
    "    record = SeqIO.read(handle, 'genbank')\n",
    "    genome_accession = record.annotations['db_source'].split(' ')[-1]\n",
    "    genome_accessions.append(genome_accession)\n",
    "\n",
    "for genome_accession in genome_accessions:\n",
    "#写入文件\n",
    "    with open('dpos_genome_accessions.txt', 'a') as f:\n",
    "        f.write(genome_accession)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open('dpos_database.txt', 'r') as file:\n",
    "    protein_accessions = file.read().splitlines()\n",
    "\n",
    "for protein_accession in protein_accessions:\n",
    "    #检查./dpos_db/valid_dpos目录下是否存在以蛋白质accession号命名的子目录\n",
    "    if not os.path.exists(f'./dpos_db/valid_dpos/{protein_accession}'):\n",
    "        print(f'./dpos_db/valid_dpos/{protein_accession} does not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取published_dpos_genome.tsv\n",
    "import pandas as pd\n",
    "from Bio import Entrez, SeqIO\n",
    "import os\n",
    "\n",
    "published_dpos_genome = pd.read_csv('published_dpos_genome.tsv', sep='\\t', header=None)\n",
    "\n",
    "published_dpos_genome.columns = ['protein_accession', 'genome_accession']\n",
    "\n",
    "#接下来的任务是遍历这个表，根据每行的protein_accession,进入/public/yxshen/DposFinderWeb/server/dpos_db/valid_dpos/protein_accession目录下,然后从\n",
    "#NCBI下载对应的基因组序列，保存为genome.gb文件\n",
    "\n",
    "Entrez.email = 'shenyanxiang@sjtu.edu.cn'\n",
    "\n",
    "for index, row in published_dpos_genome.iterrows():\n",
    "    protein_accession = row['protein_accession']\n",
    "    genome_accession = row['genome_accession']\n",
    "    if not os.path.exists(f'./dpos_db/valid_dpos/{protein_accession}'):\n",
    "        print(f'./dpos_db/valid_dpos/{protein_accession} does not exist')\n",
    "    else:\n",
    "        handle = Entrez.efetch(db='nucleotide', id=genome_accession, rettype='gb', retmode='text')\n",
    "        record = SeqIO.read(handle, 'genbank')\n",
    "        with open(f'./dpos_db/valid_dpos/{protein_accession}/genome.gb', 'w') as f:\n",
    "            SeqIO.write(record, f, 'genbank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "published_dpos_genome = pd.read_csv('published_dpos_genome.tsv', sep='\\t', header=None)\n",
    "published_dpos_genome.columns = ['protein_accession', 'genome_accession']\n",
    "\n",
    "for index, row in published_dpos_genome.iterrows():\n",
    "    protein_accession = row['protein_accession']\n",
    "    genome_accession = row['genome_accession']\n",
    "    genome_features = pd.DataFrame(columns=['id', 'protein_id', 'annotation', 'locus_tag', 'gene', 'start', 'end', 'strand', 'accession'])\n",
    "    if not os.path.exists(f'./dpos_db/valid_dpos/{protein_accession}'):\n",
    "        print(f'./dpos_db/valid_dpos/{protein_accession} does not exist')\n",
    "    else:\n",
    "        with open(f'./dpos_db/valid_dpos/{protein_accession}/genome.gb', 'r') as f:\n",
    "            record = SeqIO.read(f, 'genbank')\n",
    "            id_counter = 1  # 计数器变量\n",
    "            for feature in record.features:\n",
    "                if feature.type == 'CDS':\n",
    "                    protein_id = feature.qualifiers['protein_id'][0] if 'protein_id' in feature.qualifiers else ''\n",
    "                    annotation = feature.qualifiers['product'][0] if 'product' in feature.qualifiers else ''\n",
    "                    locus_tag = feature.qualifiers['locus_tag'][0] if 'locus_tag' in feature.qualifiers else f'gp{id_counter}'\n",
    "                    gene = feature.qualifiers['gene'][0] if 'gene' in feature.qualifiers else ''\n",
    "                    start = feature.location.start\n",
    "                    end = feature.location.end\n",
    "                    strand = feature.location.strand\n",
    "                    accession = genome_accession\n",
    "                    genome_features = genome_features.append({'id': id_counter, 'protein_id': protein_id, 'annotation': annotation, 'locus_tag': locus_tag, 'gene': gene, 'start': start, 'end': end, 'strand': strand, 'accession': accession}, ignore_index=True)\n",
    "                    id_counter += 1\n",
    "\n",
    "    genome_features.to_csv(f'./dpos_db/valid_dpos/{protein_accession}/genome_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "published_dpos_genome = pd.read_csv('published_dpos_genome.tsv', sep='\\t', header=None)\n",
    "published_dpos_genome.columns = ['protein_accession', 'genome_accession']\n",
    "\n",
    "published_dpos_genome = published_dpos_genome[published_dpos_genome['protein_accession'] != 'NP_690860.1']\n",
    "\n",
    "for index, row in published_dpos_genome.iterrows():\n",
    "    protein_accession = row['protein_accession']\n",
    "    print(protein_accession)\n",
    "    genome_accession = row['genome_accession']\n",
    "    features = pd.read_csv(f'./dpos_db/valid_dpos/{protein_accession}/genome_features.csv')\n",
    "    center = features[features['protein_id'].apply(lambda x: x.split('.')[0]) == protein_accession.split('.')[0]]['id']\n",
    "    center = int(center)\n",
    "    \n",
    "    context = features[abs(features['id'] - center) <= 5]\n",
    "\n",
    "    names = [f'{locus_tag} ({gene})' if isinstance(gene, str) else locus_tag for gene, locus_tag in zip(\n",
    "            context['gene'], context['locus_tag'])]\n",
    "    orietations = [1 if strand == '+' else -1 for strand in context['strand']]\n",
    "    colors = ['red' if id == center else 'gray' for id in context['id']]\n",
    "\n",
    "    context.loc[:, 'name'] = names\n",
    "    context.loc[:, 'orietation'] = orietations\n",
    "    context.loc[:, 'color'] = colors\n",
    "\n",
    "    context.to_csv(f'./dpos_db/valid_dpos/{protein_accession}/genes.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "published_dpos_genome = pd.read_csv('published_dpos_genome.tsv', sep='\\t', header=None)\n",
    "published_dpos_genome.columns = ['protein_accession', 'genome_accession']\n",
    "\n",
    "published_dpos_genome = published_dpos_genome[published_dpos_genome['protein_accession'] != 'NP_690860.1']\n",
    "\n",
    "#将protein_accession号写入accession.tsv文件\n",
    "\n",
    "published_dpos_genome['protein_accession'].to_csv('accession.tsv', sep='\\t', index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DposFinder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
